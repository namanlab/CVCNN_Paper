# Phase-Aware Deep Learning with Complex-Valued CNNs for Audio Signal Applications

This repository contains the implementation for the experiments described in the paper:  
**Phase-Aware Deep Learning with Complex-Valued CNNs for Audio Signal Applications**  

It includes code, datasets, and notebooks for:  
- **Experiment 1** â€“ Baseline image classification on MNIST, KMNIST, and Fashion-MNIST  
- **Experiment 2** â€“ Audio signal classification with MFCCs (Binary & Multi-class)  
- **Experiment 3** â€“ Phase-aware Graph Neural Network (GNN) audio experiments  

---

## ğŸ“‚ Repository Structure

```
.
â”œâ”€â”€ data/                     # All dataset folders and preprocessed features
â”‚   â”œâ”€â”€ FashionMNIST/raw/
â”‚   â”œâ”€â”€ KMNIST/raw/
â”‚   â”œâ”€â”€ MNIST/raw/
â”‚   â”œâ”€â”€ music_genre_binary_data/
â”‚   â”œâ”€â”€ music_genre_multiclass_data/
â”‚
â”œâ”€â”€ results/                  # Saved experimental outputs (plots, logs, metrics)
â”‚
â”œâ”€â”€ EXP1_MNIST.ipynb           # Experiment 1 â€“ MNIST
â”œâ”€â”€ EXP1_KMNIST.ipynb          # Experiment 1 â€“ KMNIST
â”œâ”€â”€ EXP1_FMNIST.ipynb          # Experiment 1 â€“ Fashion-MNIST
â”œâ”€â”€ EXP2_3_Binary_MusicGenre.ipynb   # Experiments 2 and 3 â€“ Binary genre classification
â”œâ”€â”€ EXP2_3_Multi_MusicGenre.ipynb    # Experiments 2 and 3 â€“ Multi-class genre classification
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## âš™ï¸ System & Environment Details

All experiments were conducted locally on a:

- **Machine:** MacBook Pro (Model MPHE3HN/A)  
- **OS:** macOS 14.5 (Sonoma)  
- **Chip:** Apple M2 Pro (10 cores: 6 performance + 4 efficiency)  
- **RAM:** 16 GB unified memory  
- **Python:** 3.11  
- **Backend:** PyTorch with Metal acceleration for Apple Silicon  

**Training was CPU-based**, leveraging Apple Silicon's accelerated linear algebra operations.

---

## ğŸ“¦ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/<your-username>/<repo-name>.git
cd <repo-name>
```

###  2ï¸âƒ£ Create a virtual environment (recommended)

```bash
python3.11 -m venv env
source env/bin/activate   # On macOS / Linux
env\Scripts\activate      # On Windows
```

###  3ï¸âƒ£ Install dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

---

## ğŸ“œ Requirements

`requirements.txt` includes:

```
torch
torchvision
complexPyTorch
matplotlib
seaborn
numpy
json5
librosa
scipy
pathlib
scikit-learn
```

---

## ğŸš€ Running Experiments

### **Experiment 1: Image Classification with CVCNNs**

Run any of the three notebooks for MNIST, KMNIST, or Fashion-MNIST:

```bash
jupyter notebook EXP1_MNIST.ipynb
jupyter notebook EXP1_KMNIST.ipynb
jupyter notebook EXP1_FMNIST.ipynb
```

### **Experiments 2 & 3: Audio Genre Classification & Phase-Aware GNNs**

These notebooks contain both:

- Experiment 2 â€“ MFCC-based CNN classification (Binary & Multi-class). 
- Experiment 3 â€“ Phase-aware GNN classification. 

Binary Genre Classification (Rock vs Classical):

```bash
jupyter notebook EXP2_3_Binary_MusicGenre.ipynb
```

Multi-class Genre Classification:

```bash
jupyter notebook EXP2_3_Multi_MusicGenre.ipynb
```



## ğŸ¯ Notes
- All datasets are stored in the `data/` directory.  
- Audio feature extraction uses **Librosa**; MFCC workflows are detailed in the paper.  

---

## ğŸ“„ License
This project is licensed under the terms of the **MIT License**. See the [LICENSE](LICENSE) file for details.

